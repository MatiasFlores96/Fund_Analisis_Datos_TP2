---
title: "Trabajo Practico N°1"
author: "Ing. Flores, Matias & Ing. Loiseau, Matias"
format: pdf
editor: visual
---

```{r, message=FALSE, warning=FALSE}
library(rstudioapi)
library(readxl)
library(ggplot2)
library(tidyverse)
library(GGally)
library(ggthemes)
library(effectsize)
library(car)
library("nortest")

```

# Ejercicio N°1

## Punto 1

### Carga del Data Set

```{r}
setwd(dirname(getActiveDocumentContext()$path))
```

```{r, message=FALSE, warning=FALSE}
MedidasCorporales <- read_excel("MedidasCorporales.xlsx")
attach(MedidasCorporales)
```

Ponemos esto para saber cuantos registros y variables hay. Y si son todas numericas

```{r}
str(MedidasCorporales)
```

Verificamos que no haya nulos en el dataset

```{r}
which(is.na(MedidasCorporales))

```

Scatterplot

```{r}
ggplot(data = MedidasCorporales, aes(x = Peso, y = Altura)) +
  geom_point(col = "violet") +
  xlab("Altura del padre (en cm)") +
  ylab("Altura del hijo (en cm)")
```

```{r}
cor(Peso, Altura)
```

Usamos y chirimbolo x. Donde predecimos el peso en base a la altura. Esto responde como influye la altura en el peso. En el ejemplo de la profesora, es como influye la altura del padre en la del hijo.

```{r}
reg_lineal <- lm(formula = Peso ~ Altura, 
                  data = MedidasCorporales)
reg_lineal
```

```{r}
reg_lineal$coefficients
```

```{r}
ggplot(data = MedidasCorporales, aes(x = Altura, y = Peso)) +
  geom_point(col = "pink") +
  geom_abline(slope = 1.018, intercept = -105.011, color = "purple") +
  xlab("Altura del padre (en cm)") +
  ylab("Altura del hijo (en cm)")
```

```{r}
summary(reg_lineal)
```

Los coeficientes de regresion son muy significativos.

```{r}
residuos <- data.frame(Error = reg_lineal$residuals)

ggplot(data = residuos, aes(x = Error)) +
  geom_histogram(fill = "pink", col = "purple") +
  ylab("")

ggqqplot(data = residuos, x = "Error", color = "violet", pch = 16)

shapiro.test(residuos$Error)
```

No se aprecia normalidad en los residuos.

## Punto 3

```{r}
n = 507
set.seed(1234)
```

```{r}
library(lattice)
library(caret)

```

```{r}
muestras <- 1:n %>% 
  createDataPartition(p=0.80, list=FALSE)
```

```{r}

entrenamiento_tp <- MedidasCorporales[muestras,]
prueba_tp <- MedidasCorporales[-muestras,]
```

```{r}
entrenamiento_tp
```

```{r}
reg_multiple = lm(formula=Peso ~ ., data = entrenamiento_tp)
```

```{r}
reg_multiple
```

```{r}
confint(reg_multiple , level=0.95)
```

```{r}
reg_multiple_nueva = lm(formula=Peso ~ `Profundidad de pecho` + `Diámetro de rodilla` + `Contorno de pecho` + `Contorno de cintura`+
                          `Contorno de cadera` + `Contorno de muslo` + `Contorno de antebrazo` + `Contorno de rodilla` + 
                          `Contorno de pantorrilla` + Edad + Altura, data = entrenamiento_tp)
```

```{r}
summary(reg_multiple)
```

```{r}
options(width = 80) # (mejora visual de la salida)

predicciones1 <- predict(reg_multiple, prueba_tp, type = "response")

predicciones1
```

```{r}
summary(reg_multiple_nueva)
```

```{r}
options(width = 80) # (mejora visual de la salida)

predicciones2 <- predict(reg_multiple_nueva, prueba_tp, type = "response")

predicciones2
```

```{r}
prueba_tp
```

```{r}
data1 <- data.frame(pred = predicciones1, actual = prueba_tp$Peso)
data1
```

```{r}
data2 <- data.frame(pred = predicciones2, actual = prueba_tp$Peso)
data2
```

```{r}
MSE_Modelo1 = mean((data1$actual - data1$pred)^2)
MSE_Modelo2 = mean((data2$actual - data2$pred)^2)
MSE_Modelo1
MSE_Modelo2
```

# Ejercicio N°2

```{r, message=FALSE, warning=FALSE}
Dolor <- read_excel("Dolor.xlsx")
attach(Dolor)
```

```{r, message=FALSE, warning=FALSE}
Dolor_Nuevo <- drop_na(Dolor)
attach(Dolor_Nuevo)
```

```{r}
nrow(Dolor_Nuevo)
```

```{r}
which(is.na(Dolor))

```

```{r}
str(Dolor_Nuevo)
```

```{r}
df2<-Dolor_Nuevo[!(Dolor_Nuevo$Colesterol=="NA"),]
df2
```

```{r}
df2$Colesterol <- as.numeric(as.character(df2$Colesterol))  # Convert one variable to numeric

```

```{r}
df2
```

```{r}
log_simple <- glm(formula = `Estrechamiento arterias coronarias` ~ Colesterol,
                  data = df2,
                  family = "binomial")
summary(log_simple)
```

```{r}
nuevo_valor <- data.frame(Colesterol = c(199))
prob <- log_simple %>% predict(nuevo_valor, type = "response")
prob
```

```{r}
log_simple_multi <- glm(formula = `Estrechamiento arterias coronarias` ~ Edad + `Días con síntomas` + Colesterol,
                  data = df2,
                  family = "binomial")
summary(log_simple_multi)
```

No tiene significancia dias con sintoma. Los otros dos tienen una fuerte signficancia.

```{r}

Masculino <- df2 %>%
  filter(Sexo == 0)

Femenino <- df2 %>%
  filter(Sexo == 1)
```

```{r}
log_simple_multi_M <- glm(formula = `Estrechamiento arterias coronarias` ~ Edad + `Días con síntomas` + Colesterol,
                  data = Masculino,
                  family = "binomial")
summary(log_simple_multi_M)
```

```{r}
log_simple_multi_F <- glm(formula = `Estrechamiento arterias coronarias` ~ Edad + `Días con síntomas` + Colesterol,
                  data = Femenino,
                  family = "binomial")
summary(log_simple_multi_F)
```

# Ejercicio N°3

```{r, message=FALSE, warning=FALSE}
Europa <- read_excel("Europa.xlsx")
attach(Europa)

```

```{r}
Europa
```

```{r}
Países <- Europa %>%
  dplyr::select(Área, PBI, Inflación, `Expectativa de vida`, `Población militar`, 
                `Crecimiento de la población`, `Tasa de desempleo`)
```

```{r}
Sigma_P = cov(Países)
Sigma_P
```

```{r}
Inv = det(Sigma_P)
Inv
```

Como es distinta a 0 es inversible

```{r}
autovalores_p <- eigen(Sigma_P)$values
autovalores_p
```

Creemos que area

```{r}
options(width = 80) # (mejora visual de la salida)

PC_p <- prcomp(Países, scale = TRUE)
PC_p$rotation
```

```{r}
options(width = 80) # (mejora visual de la salida)

summary(PC_p)

```

Grafico del codo

Punto 5. Contribucion de variables-

```{r}
fviz_pca_var(PC_p, repel = TRUE,  
             col.var = "contrib", # según la contribución
             gradient.cols = "Set1",
             title = "",
             legend.title = "") 
```

# Ejercicio N°4

```{r, message=FALSE, warning=FALSE}
data("JohnsonJohnson")

```

```{r}
JohnsonJohnson
```

```{r}
help("JohnsonJohnson")
```

El dataset contiene las ganancias en dolares trimestrales, desde el año 1960 hasta 1980.

```{r}
class(JohnsonJohnson)
```

```{r}
length(JohnsonJohnson)
```

```{r}
plot.ts(JohnsonJohnson, col ="royalblue", xlab = "Año", ylab = "Ganancias")
```

Descomposicion Aditiva

```{r}
ganancias_da <- decompose(JohnsonJohnson, type = "additive")
```

## 

```{r}
plot.ts(ganancias_da$trend, col = "purple", xlab = "Año", ylab = "Ganancias")
```

```{r}
varR <- var(na.omit(ganancias_da$random))
varTR <- var(na.omit(ganancias_da$trend) + na.omit(ganancias_da$random))
1 - varR / varTR
```

Tiene una fuerte tendencia porque se desvía hacia arriba con un fuerza de 0.97, al parecer.

```{r}
plot.ts(ganancias_da$seasonal, col = "violet", xlab = "Año", ylab = "Ganancias")
```

```{r}
varR <- var(na.omit(ganancias_da$random))
varSR <- var(na.omit(ganancias_da$seasonal) + na.omit(ganancias_da$random))
1 - varR / varSR
```

Se observa una debil estacionalidad. Tiene una fuerza de 0.32.

AGREGAR MULTIPLICATIVA. SI PINTA AGREGAR LAG.

BOXCOX

```{r}
lamb <- BoxCox.lambda(JohnsonJohnson)
lamb
```

```{r}
JohnBC <- BoxCox(JohnsonJohnson, lambda = lamb)
```

```{r}
sto <- autoplot(JohnsonJohnson, color = "royalblue", main =  "Serie de tiempo original", xlab = "", ylab = "") +
  theme_hc() +
  theme(plot.title = element_text(hjust = 0.5))

stt <- autoplot(JohnBC, color = "purple", main =  "Serie de tiempo transformada", xlab = "", ylab = "") +
  theme_hc() +
  theme(plot.title = element_text(hjust = 0.5))

grid.arrange(sto, stt, ncol = 1)
```

```{r}
JohnBC
```

```{r}
entrenamiento_john <- window(JohnBC, end = c(1960,76))
prueba_john <- window(JohnBC, start = c(1977,9))
prueba_john
```

```{r, message=FALSE, warning=FALSE}
library(fpp2)
PP.test(JohnBC)
```

```{El p valor resultante fue menor que 0.05, por lo cual determinamos que la transofrmada de box cox es estacionaria.}
```

```{r}
Acf(JohnBC, lag.max = 14, type = "partial", main = "") 
```

Elegimos como p a 5, porque observamos que a partir del lag 5 los valores se van acercando signficativamente a 0.

```{r}
Acf(JohnBC, lag.max = 30, type = "correlation", main = "") 
```

```{r}
JOHN_dif <- diff(JohnBC)
autoplot(JOHN_dif, color = "royalblue", xlab = "Tiempo", ylab = "Precios diferenciados")
```

```{r}
Acf(JOHN_dif, lag.max = 14, type = "partial", main = "") 
```

```{r}
Acf(JOHN_dif, lag.max = 30, type = "correlation", main = "") 
```

```{r}
JOHN_dif_2 <- diff(JOHN_dif)
autoplot(JOHN_dif_2, color = "royalblue", xlab = "Tiempo", ylab = "Precios diferenciados")
```

```{r}
Acf(JOHN_dif_2, lag.max = 14, type = "partial", main = "") 
```

```{r}
Acf(JOHN_dif_2, lag.max = 30, type = "correlation", main = "") 
```

```{r}
JOHN_dif_3 <- diff(JOHN_dif_2)
```

```{r}
Acf(JOHN_dif_3, lag.max = 30, type = "correlation", main = "") 
```

```{r}
JOHN_dif_3 <- diff(JOHN_dif_2)
JOHN_dif_4 <- diff(JOHN_dif_3)
JOHN_dif_5 <- diff(JOHN_dif_4)
```

```{r}
Acf(JOHN_dif_5, lag.max = 30, type = "correlation", main = "") 
```

```{r}
JOHN_dif_6 <- diff(JOHN_dif_5)
JOHN_dif_7 <- diff(JOHN_dif_6)
JOHN_dif_8 <- diff(JOHN_dif_7)
```

```{r}
Acf(JOHN_dif_8, lag.max = 14, type = "partial", main = "") 
```

```{r}
Acf(JOHN_dif_8, lag.max = 30, type = "correlation", main = "") 
```

eLEGIMOS Q=16 Y P=5

```{r}
kpss.test(JOHN_dif)
```

Vemos que haciendo la dif 1 nos da eestacionario.

```{r}
ARIMA <- arima(entrenamiento_john, order = c(16,3,5), method = "ML")
round(summary(ARIMA)$coef, 4)
```

```{r}
predARIMA <- forecast(ARIMA, h = 8)
predARIMA
```

```{r}
options(width = 80) # mejora la visual de la salida

accuracy(predARIMA, prueba_john)
```

AUTOMATICO

```{r}
autoARIMA <- auto.arima(entrenamiento_john)
summary(autoARIMA)
```

```{r}
pred_autoARIMA <- forecast(autoARIMA, h = 8)
```

```{r}
options(width = 80) # mejora la visual de la salida

accuracy(pred_autoARIMA, prueba_john)
```
